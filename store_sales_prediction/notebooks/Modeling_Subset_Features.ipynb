{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.14.3\n",
      "pandas 0.23.0\n",
      "xgboost 0.72\n",
      "sklearn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for p in [np, pd, xgb, sklearn]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import PredefinedSplit, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "61252fda3dc0f9da853960bb3ea85954d11097b3"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "00cb3e0e90b2028f8bcbdae97cb02761f5eedbe5"
   },
   "outputs": [],
   "source": [
    "# Evaluation criterion\n",
    "def smape(pred, actual):\n",
    "    \"\"\"\n",
    "    pred: a numpy array of predictions\n",
    "    actual: a numpy array of actual values\n",
    "    \n",
    "    for a perfectly predicted zero observation, the smape is defined to be 0. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    selector = ~((pred == 0) & (actual == 0))\n",
    "    numerator = np.abs(pred-actual)\n",
    "    denom = (np.abs(pred) + np.abs(actual)) / 2\n",
    "    return 100*np.sum((numerator[selector] / denom[selector])) / pred.shape[0]\n",
    "\n",
    "smape_scorer = make_scorer(smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "116700728b81cfb860671df95dce74cbbdf09b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.142857142857142\n",
      "71.2121212121212\n",
      "85.85858585858585\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "for actual, pred in zip([np.array([1,4,0,5])]*3, \n",
    "                        [np.array([1,3,0,5]), np.array([0.5,4,1,6]), np.array([2,7,-1,4])]):\n",
    "    print(smape(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "602f4c8732d84447cd31d111767cf22850bbb4c7"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv.zip\")\n",
    "test = pd.read_csv(\"../input/test.csv.zip\")\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "89f4ceea57b94303b9f1cf40da1ad07dbaa780b4"
   },
   "outputs": [],
   "source": [
    "# Convert the date field\n",
    "train.loc[:,'date'] = pd.to_datetime(train.date)\n",
    "test.loc[:,'date'] = pd.to_datetime(test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6a0feb728d049552f79c8619256f998419bd4db1"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test], sort=False).fillna(0)   # test data has id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "9afeb53e1b99486eb03691c5b29067302b2a6e3b"
   },
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5dd99d8242f016adccfc241858774b60baf71bfa"
   },
   "outputs": [],
   "source": [
    "data = downcast_dtypes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "0add3eed85dbdd45a1ad38e968c9868a3f8c19bf"
   },
   "outputs": [],
   "source": [
    "# Lag featurizer\n",
    "class Lag_Featurizer(TransformerMixin):\n",
    "    def __init__(self, index_col, time_col, value_col, output_col, output_time_index=False, shift=0, freq='1D'):\n",
    "        self.index_col = index_col\n",
    "        self.time_col = time_col\n",
    "        self.value_col = value_col\n",
    "        self.output_col = output_col\n",
    "        self.output_time_index=output_time_index\n",
    "        self.shift = shift\n",
    "        self.freq = freq\n",
    "        \n",
    "    def fit(self, X):                \n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        assert isinstance(self.index_col, list)\n",
    "        \n",
    "        time_key = pd.Grouper(freq=self.freq)      \n",
    "        time_index = self.index_col + [time_key]\n",
    "        resampled = X.groupby(time_index)[self.value_col].sum().reset_index().set_index(self.time_col)\n",
    "        shifted= resampled.groupby(self.index_col).shift(self.shift, freq=self.freq).drop(self.index_col, axis=1).reset_index().rename(columns={self.value_col:self.output_col})\n",
    "        merged = pd.merge(X, shifted, how='left',left_on=self.index_col + [self.time_col], right_on=self.index_col + [self.time_col])\n",
    "        if self.output_time_index:\n",
    "            return merged.set_index(self.time_col)\n",
    "        else:\n",
    "            return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d835b173562a5bef8510cb55f96ccfb9df752a7",
    "collapsed": true
   },
   "source": [
    "#### Add lag features\n",
    "Store-item lag sales\n",
    "\n",
    "store lag sales\n",
    "\n",
    "item lag sales\n",
    "\n",
    "lag periods (days): 1, 2, 3, 4, 7, 14, 21, 28,  84, 168, 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "34ef65e0d276829a6e89e885e0458577f1157730"
   },
   "outputs": [],
   "source": [
    "data = data.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5837183b6b5ded61904711f333c448b6238011cd",
    "collapsed": true
   },
   "source": [
    "#### Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4e2faa663393437cf13a0daab21c98fd2a410e2b"
   },
   "outputs": [],
   "source": [
    "# 2018-01 ~ 2018-03, a total of 92 days\n",
    "lag_feature_pipeline = Pipeline(\n",
    "[\n",
    "    # lag store, item sales\n",
    "    \n",
    "    ('store_item_lag_3m',   Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m',   output_time_index=True, shift=98))\n",
    "#     ('store_item_lag_3m_1', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_1', output_time_index=True, shift=99)),\n",
    "#     ('store_item_lag_3m_2', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_2', output_time_index=True, shift=100)),\n",
    "#     ('store_item_lag_3m_3', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_3', output_time_index=True, shift=101)),\n",
    "#     ('store_item_lag_3m_4', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_4', output_time_index=True, shift=102)),\n",
    "#     ('store_item_lag_3m_5', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_5', output_time_index=True, shift=103)),\n",
    "#     ('store_item_lag_3m_6', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',output_col='sales_3m_6', output_time_index=True, shift=104)),   \n",
    "#     ('store_item_lag_4m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',  output_col='sales_4m',     output_time_index=True, shift=112)),\n",
    "#     ('store_item_lag_5m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',  output_col='sales_5m',     output_time_index=True, shift=140)),\n",
    "#     ('store_item_lag_6m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',  output_col='sales_6m',     output_time_index=True, shift=168)),\n",
    "#     ('store_item_lag_9m', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',  output_col='sales_9m',     output_time_index=True, shift=252)),\n",
    "#     ('store_item_lag_1y', Lag_Featurizer(index_col=['store', 'item'],time_col='date',value_col='sales',  output_col='sales_1y',     output_time_index=True, shift=336))\n",
    "    \n",
    "    #lag store sales\n",
    "#     ('store_lag_3m',   Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m',   output_time_index=True, shift=98)),\n",
    "#     ('store_lag_3m_1', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_1', output_time_index=True, shift=99)),\n",
    "#     ('store_lag_3m_2', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_2', output_time_index=True, shift=100)),\n",
    "#     ('store_lag_3m_3', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_3', output_time_index=True, shift=101)),\n",
    "#     ('store_lag_3m_4', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_4', output_time_index=True, shift=102)),\n",
    "#     ('store_lag_3m_5', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_5', output_time_index=True, shift=103)),\n",
    "#     ('store_lag_3m_6', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales',output_col='store_sales_3m_6', output_time_index=True, shift=104)),   \n",
    "#     ('store_lag_4m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales', output_col='store_sales_4m',    output_time_index=True, shift=112)),\n",
    "#     ('store_lag_5m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales', output_col='store_sales_5m',    output_time_index=True, shift=140)),\n",
    "#     ('store_lag_6m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales', output_col='store_sales_6m',    output_time_index=True, shift=168)),\n",
    "#     ('store_lag_9m', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales', output_col='store_sales_9m',    output_time_index=True, shift=252)),\n",
    "#     ('store_lag_1y', Lag_Featurizer(index_col=['store'],time_col='date',value_col='sales', output_col='store_sales_1y',    output_time_index=True, shift=336)),\n",
    "    \n",
    "    # lag item sales\n",
    "#     ('item_lag_3m',   Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m',   output_time_index=True, shift=98)),\n",
    "#     ('item_lag_3m_1', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_1', output_time_index=True, shift=99)),\n",
    "#     ('item_lag_3m_2', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_2', output_time_index=True, shift=100)),\n",
    "#     ('item_lag_3m_3', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_3', output_time_index=True, shift=101)),\n",
    "#     ('item_lag_3m_4', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_4', output_time_index=True, shift=102)),\n",
    "#     ('item_lag_3m_5', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_5', output_time_index=True, shift=103)),\n",
    "#     ('item_lag_3m_6', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',output_col='item_sales_3m_6', output_time_index=True, shift=104)),   \n",
    "#     ('item_lag_4m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',  output_col='item_sales_4m',   output_time_index=True, shift=112)),\n",
    "#     ('item_lag_5m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',  output_col='item_sales_5m',   output_time_index=True, shift=140)),\n",
    "#     ('item_lag_6m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',  output_col='item_sales_6m',   output_time_index=True, shift=168)),\n",
    "#     ('item_lag_9m', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',  output_col='item_sales_9m',   output_time_index=True, shift=252)),\n",
    "#     ('item_lag_1y', Lag_Featurizer(index_col=['item'],time_col='date',value_col='sales',  output_col='item_sales_1y',   output_time_index=True, shift=336)),\n",
    "\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a3639a5c941fcf30092b88e36fc5753c70c276fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%time data = lag_feature_pipeline.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "5ebf0d59adda02e012d05a94caab6ebbab6e93d5"
   },
   "outputs": [],
   "source": [
    "# drop all rows with nulls. Part of 2013 data is kept since the maximum lag is 336 days. \n",
    "data.dropna(inplace=True)\n",
    "data.loc[:,'weekend'] = ((data.index.weekday == 5) |  (data.index.weekday == 6)) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "54898dc541df267606d7b51b2fac1d67cd3692e8"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \n",
    "    'sales',\n",
    "\n",
    "    'sales_3m',  \n",
    "#     'sales_3m_1',\n",
    "#     'sales_3m_2',\n",
    "#     'sales_3m_3',\n",
    "#     'sales_3m_4',\n",
    "#     'sales_3m_5',\n",
    "#     'sales_3m_6',\n",
    "#     'sales_4m',  \n",
    "#     'sales_5m',  \n",
    "#     'sales_6m',  \n",
    "#     'sales_9m',  \n",
    "#     'sales_1y',\n",
    "\n",
    "#     'store_sales_3m',  \n",
    "#     'store_sales_3m_1',\n",
    "#     'store_sales_3m_2',\n",
    "#     'store_sales_3m_3',\n",
    "#     'store_sales_3m_4',\n",
    "#     'store_sales_3m_5',\n",
    "#     'store_sales_3m_6',\n",
    "#     'store_sales_4m',\n",
    "#     'store_sales_5m',\n",
    "#     'store_sales_6m',\n",
    "#     'store_sales_9m',\n",
    "#     'store_sales_1y',\n",
    "\n",
    "#     'item_sales_3m',  \n",
    "#     'item_sales_3m_1',\n",
    "#     'item_sales_3m_2',\n",
    "#     'item_sales_3m_3',\n",
    "#     'item_sales_3m_4',\n",
    "#     'item_sales_3m_5',\n",
    "#     'item_sales_3m_6',\n",
    "#     'item_sales_4m',  \n",
    "#     'item_sales_5m',  \n",
    "#     'item_sales_6m',  \n",
    "#     'item_sales_9m',  \n",
    "#     'item_sales_1y',  \n",
    "\n",
    "    'weekend'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "377610ab8c61f6ffde84ae89a6c842ca3172a64e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation samples = 45000\n"
     ]
    }
   ],
   "source": [
    "training = data.loc['2016-01':'2017-03',cols]\n",
    "validation_split = np.where((training.index >= pd.Timestamp(2017,1,1)) & (training.index <= pd.Timestamp(2017,3,31)), 0, -1)\n",
    "print('Number of validation samples = {0}'.format(np.sum(validation_split==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "4b18946c6a48b81cce5d16ba02441859919adbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 45000\n",
      "Number of features           = 2\n",
      "Date range = 2017-01-01 to 2017-03-31\n",
      "Index(['sales_3m', 'weekend'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Validation data\n",
    "X_validation = training.loc[validation_split == 0, cols[1:]]\n",
    "y_validation = training.loc[validation_split == 0, 'sales']\n",
    "print('Number of training instances = {0:d}'.format(X_validation.shape[0]))\n",
    "print('Number of features           = {0:d}'.format(X_validation.shape[1]))\n",
    "print('Date range = {0} to {1}'.format(X_validation.index[0].strftime('%Y-%m-%d'), X_validation.index[-1].strftime('%Y-%m-%d')))\n",
    "print(X_validation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "22bbb7470d0f6240e469f2e96482aa9eff35d9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 228000\n",
      "Number of features           = 2\n",
      "Date range = 2016-01-01 to 2017-03-31\n",
      "Index(['sales_3m', 'weekend'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# training matrices\n",
    "X_training = training.loc[:,cols[1:]]\n",
    "y_training = training.loc[:,'sales']\n",
    "print('Number of training instances = {0:d}'.format(X_training.shape[0]))\n",
    "print('Number of features           = {0:d}'.format(X_training.shape[1]))\n",
    "print('Date range = {0} to {1}'.format(training.index[0].strftime('%Y-%m-%d'), training.index[-1].strftime('%Y-%m-%d')))\n",
    "print(X_training.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "0d82bc77f7b6c34e08a6d46735297b7d72e34e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test instances = 45000\n",
      "Number of features       = 2\n",
      "Date range = 2018-01-01 to 2018-03-31\n",
      "Index(['sales_3m', 'weekend'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "testing = data.loc['2018-01':,cols]\n",
    "X_testing = testing.loc[:,cols[1:]]\n",
    "y_testing = testing.loc[:,'sales']\n",
    "print('Number of test instances = {0:d}'.format(X_testing.shape[0]))\n",
    "print('Number of features       = {0:d}'.format(X_testing.shape[1]))\n",
    "print('Date range = {0} to {1}'.format(testing.index[0].strftime('%Y-%m-%d'), testing.index[-1].strftime('%Y-%m-%d')))\n",
    "print(X_testing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "9e17ed0f3480b7a84e2363285ea08bfc9f971694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 864000\n",
      "Number of features           = 2\n",
      "Date range = 2013-04-09 to 2017-12-31\n",
      "Index(['sales_3m', 'weekend'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "training_full = data.loc[:'2017-12',cols]\n",
    "X_training_full = training_full.loc[:,cols[1:]]\n",
    "y_training_full = training_full.loc[:,'sales']\n",
    "print('Number of training instances = {0:d}'.format(X_training_full.shape[0]))\n",
    "print('Number of features           = {0:d}'.format(X_training_full.shape[1]))\n",
    "print('Date range = {0} to {1}'.format(training_full.index[0].strftime('%Y-%m-%d'), training_full.index[-1].strftime('%Y-%m-%d')))\n",
    "print(X_training_full.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91bbde6ddff4b223a7c2399db48c374247f89c7d"
   },
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "f2f2a07c6201fb3979ecf17bb73952579a7462a8"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=RANDOM_STATE, criterion='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "aa96e3ba81c031dd9347800628cae49936823b6a"
   },
   "outputs": [],
   "source": [
    "rf_params = {\"n_estimators\": np.arange(10, 100, 100),\n",
    "              \"max_depth\": np.arange(1, 2, 1)\n",
    "#               \"min_samples_split\": np.arange(10,110,10),\n",
    "#               \"min_samples_leaf\": np.arange(5,10,1),\n",
    "#               \"max_leaf_nodes\": np.arange(5,15,1)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "4840eaccb98a9686b1401360e2ef6bb102a3892a"
   },
   "outputs": [],
   "source": [
    "rf = GridSearchCV(rf, rf_params, scoring='neg_mean_absolute_error', n_jobs=1, cv=PredefinedSplit(validation_split), verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "a33084e1dc480a883b8833ee34b105d920b19954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV] max_depth=1, n_estimators=10 ....................................\n",
      "[CV]  max_depth=1, n_estimators=10, score=-15.342764444444445, total= 6.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.3min finished\n",
      "Wall time: 16min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=71, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': array([10]), 'max_depth': array([1])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '2016-10':'2017-03': 2 features, n_jobs=1, max_depth=1, n_estimators=10, score=-13.76432, total=  25.3s\n",
    "# '2015-01':'2017-03': 2 features, n_jobs=1, max_depth=1, n_estimators=10, score=-15.3427, total=  6.3min;\n",
    "%time rf.fit(X_training.values,y_training.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "a33d62340634b96a87cc75c2f855429daa4f8f54"
   },
   "outputs": [],
   "source": [
    "print('Best score = {0:.4f}; Best Parameter = {1}'.format(-rf.best_score_, rf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "1ceca08049f80a25819851d38b2f70b32f9c5cb6"
   },
   "outputs": [],
   "source": [
    "rf_best = rf.best_estimator_\n",
    "rf_best.fit(X_training_full, y_training_full)\n",
    "pred_rf_best = rf_best.predict(X_testing)\n",
    "submission_rf = pd.DataFrame({'Id': sample_submission.id, 'sales': pred_rf_best})\n",
    "submission_rf.to_csv('../output/submission_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ce745cf8aaaf3f56e7acbbd2622a9fb7f3c1fb"
   },
   "source": [
    "#### xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_xgb = xgb.XGBRegressor(objective='reg:linear', booster='gbtree', n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#                 'n_estimators': np.arange(50,550,50),\n",
    "#                 'min_child_weight': np.arange(10,100,2), \n",
    "#                 'eta': [0.01], \n",
    "#                 'colsample_bytree': np.arange(0.5,1.0,0.1), \n",
    "#                 'max_depth': np.arange(1,10,1),\n",
    "#                 'subsample': [0.9], \n",
    "#                 'lambda': [1.]\n",
    "# }\n",
    "\n",
    "# fit_params={\"early_stopping_rounds\":50, \n",
    "#             \"eval_metric\" : \"mae\", \n",
    "#             \"eval_set\" : [[X_validation.values, y_validation.values]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_xgb = GridSearchCV(reg_xgb, xgb_params, scoring=None, n_jobs=8, cv=PredefinedSplit(validation_split), verbose=30, fit_params=fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
